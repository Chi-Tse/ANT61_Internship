{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from Thomas Simonini's implementation\n",
    "#https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Q%20learning/FrozenLake/Q%20Learning%20with%20FrozenLake.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = 'FrozenLake8x8-v1'\n",
    "#map = 'FrozenLake-v1'\n",
    "b_slip = True\n",
    "#custom=[\"SFFF\", \"FFFF\", \"FFFF\", \"FFFG\"]\n",
    "#env = gym.make(\"FrozenLake-v1\", desc= custom)\n",
    "env = gym.make(map, is_slippery=b_slip)\n",
    "\n",
    "#env = gym.wrappers.time_limit.TimeLimit(env, max_episode_steps=500)\n",
    "#print(env.spec.max_episode_steps)\n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "qtable = np.zeros((state_size, action_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SFFHFFFF',\n",
       " 'HHFFHHHF',\n",
       " 'FFFFHHHF',\n",
       " 'FHFFFHHH',\n",
       " 'FHFFFHFF',\n",
       " 'HHFFFHHH',\n",
       " 'FHFFFHHF',\n",
       " 'FHHHFFFG']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_map(size=8, p=0.0):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is a hole\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == \"G\":\n",
    "                        return True\n",
    "                    if res[r_new][c_new] != \"H\":\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice([\"F\", \"H\"], (size, size), p=[p, 1 - p])\n",
    "        res[0][0] = \"S\"\n",
    "        res[-1][-1] = \"G\"\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "generate_random_map(size=8, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# default values for parameter experiments\n",
    "def train_model(total_episodes: int=20000, learning_rate: float=0.6, max_steps: int=200, gamma: float=0.6, \n",
    "                epsilon: float=1, max_epsilon: float=1, min_epsilon: float=0.0001, decay_rate: float=0.00005) -> list:\n",
    "    ep_reward = []\n",
    "    rewards_1000 = []\n",
    "\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "            \n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            # qtable[new_state,:] : all the actions we can take from new state\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "            \n",
    "            total_rewards += reward\n",
    "            \n",
    "            # Update state\n",
    "            state = new_state\n",
    "            \n",
    "            # Finish episode if agent reaches reward or hole\n",
    "            if done == True: \n",
    "                break\n",
    "            \n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "        ep_reward.append(total_rewards)\n",
    "\n",
    "    rewards_1000 = np.add.reduceat(ep_reward, np.arange(0, len(ep_reward), 1000))\n",
    "    #print(rewards_1000[-1])\n",
    "    print(epsilon)\n",
    "    #write_files(qtable, rewards_1000, total_episodes, learning_rate, gamma, min_epsilon, decay_rate)\n",
    "    return [qtable, rewards_1000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(qtable: np.ndarray, rewards_1000, total_episodes: int, learning_rate: float, gamma: float, \n",
    "                min_epsilon: float, decay_rate: float):\n",
    "\n",
    "    file_name = (str(total_episodes) +'_'+ str(learning_rate) +'_'+ str(gamma) +'_'+\n",
    "                 str(min_epsilon) +'_'+ str(decay_rate))\n",
    "    # path = Path(map)\n",
    "    # path.mkdir(exist_ok=True)\n",
    "    # with open (map + '\\\\' + file_name+'.txt', 'w') as f:\n",
    "    #     f.write('Total reward in final 1000 episodes: ' + str(rewards_1000[-1]) + '\\n' +\n",
    "    #             'Total episodes: ' + str(total_episodes) + '\\n' +\n",
    "    #             'Learning rate: ' + str(learning_rate) + '\\n' +\n",
    "    #             'Gamma: ' + str(gamma) + '\\n' +\n",
    "    #             'Min epsilon: ' + str(min_epsilon) + '\\n' +\n",
    "    #             'Decay rate: ' + str(decay_rate) + '\\n \\n' +\n",
    "    #             str(qtable))\n",
    "\n",
    "    # plt.plot(np.arange(0, total_episodes/1000), rewards_1000)\n",
    "    # plt.savefig(map + '\\\\'+file_name +'.png')\n",
    "    # plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (3679759047.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def test_model(max_steps: int=200, qtable: np.ndarray):\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def test_model(qtable: np.ndarray, max_steps: int=200):\n",
    "    env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "    total_episodes = 100\n",
    "    for episode in range(total_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "            \n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                # Here, we decide to only print the last state (to see if our agent is on the goal or fall into an hole)\n",
    "                #env.render()\n",
    "                \n",
    "                # We print the number of step it took.\n",
    "                print(\"Number of steps\", step)\n",
    "                print(\"Reward:\", reward)\n",
    "                total_reward += reward\n",
    "                break\n",
    "            state = new_state\n",
    "    print('Total rewards:', total_reward,'/',total_episodes)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n",
      "0.018415638797149875\n"
     ]
    }
   ],
   "source": [
    "# Tuning parameters\n",
    "#slippery 8x8\n",
    "#gamma = 0.7344827586 0.8172413793103449 0.7344827586206897\n",
    "#learning_rate = 0.1\n",
    "#non-slip 4x4 \n",
    "# learning_rate = 0.5413793103448277\n",
    "# gamma = 0.23793103448275865 0.34827586206896555\n",
    "#slip 4x4\n",
    "# gamma = 0.8724137931034484\n",
    "\n",
    "interval = 15\n",
    "parameter_range = np.linspace(0.1,0.9,interval,endpoint=True)\n",
    "rewards = []\n",
    "#rewards_sum = [0]*interval\n",
    "\n",
    "for i in range(5):\n",
    "    for parameter in parameter_range:\n",
    "        for parameter2 in parameter_range:\n",
    "            # reset qtable\n",
    "            qtable = np.zeros((state_size, action_size))\n",
    "            qtable, rewards_1000 = train_model(total_episodes=40000, max_steps=150, learning_rate=parameter, gamma=parameter2, decay_rate=0.0001)\n",
    "            rewards.append(rewards_1000[-1])\n",
    "\n",
    "rs_rewards = np.reshape(rewards,(-1,interval,interval))\n",
    "rs_rewards_mean = np.mean(rs_rewards, axis=0)\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d-%H%M')   \n",
    "pd.DataFrame(rs_rewards_mean).to_csv(now + '.csv')\n",
    "\n",
    "#print('max reward:',max(rewards_mean), 'index:', rewards_mean.index(max(rewards_mean)))\n",
    "#print(parameter_range[rewards_mean.index(max(rewards_mean))])\n",
    "#plt.plot(parameter_range, rewards_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002578628229761946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1249fbfdaf0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tuned parameters\n",
    "if env.spec.id == 'FrozenLake8x8-v1':\n",
    "    if b_slip:\n",
    "        # 8x8 slippery settings #####################################################################\n",
    "        total_episodes = 120000        # Total episodes\n",
    "        learning_rate = 0.01           # Learning rate\n",
    "        max_steps = 200                # Max steps per episode, capped at 100 for 4x4, 200 for 8x8\n",
    "        gamma = 0.999                  # Discounting rate\n",
    "        # Exploration parameters\n",
    "        epsilon = 1.0                 # Exploration rate\n",
    "        max_epsilon = 1.0             # Exploration probability at start\n",
    "        min_epsilon = 0.0001          # Minimum exploration probability \n",
    "        decay_rate = 0.00005          # Exponential decay rate for exploration prob\n",
    "    else:\n",
    "        # 8x8 non-slippery settings  #####################################################################\n",
    "        total_episodes = 60000        # Total episodes\n",
    "        learning_rate = 0.75           # Learning rate\n",
    "        max_steps = 200                # Max steps per episode, capped at 100 for 4x4, 200 for 8x8\n",
    "        gamma = 0.9                  # Discounting rate\n",
    "        # Exploration parameters\n",
    "        epsilon = 1.0                 # Exploration rate\n",
    "        max_epsilon = 1.0             # Exploration probability at start\n",
    "        min_epsilon = 0.0001            # Minimum exploration probability \n",
    "        decay_rate = 0.00005             # Exponential decay rate for exploration prob\n",
    "\n",
    "elif env.spec.id == 'FrozenLake-v1':\n",
    "    if b_slip:\n",
    "        # 4x4 slippery settings  #####################################################################\n",
    "        total_episodes = 120000        # Total episodes\n",
    "        learning_rate = 0.1 #0.15517\n",
    "           # Learning rate\n",
    "        max_steps = 200                # Max steps per episode, capped at 100 for 4x4, 200 for 8x8\n",
    "        gamma = 0.9                  # Discounting rate\n",
    "        # Exploration parameters\n",
    "        epsilon = 1.0                 # Exploration rate\n",
    "        max_epsilon = 1.0             # Exploration probability at start\n",
    "        min_epsilon = 0.0001            # Minimum exploration probability \n",
    "        decay_rate = 0.00005             # Exponential decay rate for exploration prob\n",
    "    else:\n",
    "        # 4x4 non-slippery settings  #####################################################################\n",
    "        total_episodes = 60000        # Total episodes\n",
    "        learning_rate = 0.5413793103448277           # Learning rate\n",
    "        max_steps = 200                # Max steps per episode, capped at 100 for 4x4, 200 for 8x8\n",
    "        gamma = 0.23793103448275865                  # Discounting rate\n",
    "        # Exploration parameters\n",
    "        epsilon = 1.0                 # Exploration rate\n",
    "        max_epsilon = 1.0             # Exploration probability at start\n",
    "        min_epsilon = 0.0001            # Minimum exploration probability \n",
    "        decay_rate = 0.00005             # Exponential decay rate for exploration prob\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "qtable, rewards_1000 = train_model(total_episodes, learning_rate, max_steps, gamma, \n",
    "                    epsilon, max_epsilon, min_epsilon, decay_rate)\n",
    "plt.plot(np.arange(0, total_episodes/1000), rewards_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n",
      "Number of steps 37\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "Number of steps 67\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "Number of steps 64\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "Number of steps 14\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "Number of steps 20\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  5\n",
      "Number of steps 23\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  6\n",
      "Number of steps 8\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  7\n",
      "Number of steps 76\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  8\n",
      "Number of steps 51\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  9\n",
      "Number of steps 86\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  10\n",
      "Number of steps 22\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  11\n",
      "Number of steps 31\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  12\n",
      "Number of steps 43\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  13\n",
      "Number of steps 54\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  14\n",
      "Number of steps 19\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  15\n",
      "Number of steps 55\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  16\n",
      "Number of steps 7\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  17\n",
      "Number of steps 68\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  18\n",
      "Number of steps 21\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  19\n",
      "Number of steps 25\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  20\n",
      "Number of steps 12\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  21\n",
      "Number of steps 25\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  22\n",
      "Number of steps 17\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  23\n",
      "Number of steps 22\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  24\n",
      "Number of steps 71\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  25\n",
      "Number of steps 15\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  26\n",
      "Number of steps 20\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  27\n",
      "Number of steps 11\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  28\n",
      "Number of steps 41\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  29\n",
      "Number of steps 13\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  30\n",
      "Number of steps 71\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  31\n",
      "Number of steps 72\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  32\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  33\n",
      "Number of steps 16\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  34\n",
      "Number of steps 20\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  35\n",
      "Number of steps 46\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  36\n",
      "Number of steps 26\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  37\n",
      "Number of steps 34\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  38\n",
      "Number of steps 57\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  39\n",
      "Number of steps 34\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  40\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  41\n",
      "Number of steps 14\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  42\n",
      "Number of steps 85\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  43\n",
      "Number of steps 13\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  44\n",
      "Number of steps 38\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  45\n",
      "Number of steps 89\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  46\n",
      "Number of steps 43\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  47\n",
      "Number of steps 23\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  48\n",
      "Number of steps 23\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  49\n",
      "Number of steps 26\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  50\n",
      "Number of steps 41\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  51\n",
      "Number of steps 18\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  52\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  53\n",
      "Number of steps 67\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  54\n",
      "Number of steps 20\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  55\n",
      "Number of steps 28\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  56\n",
      "Number of steps 16\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  57\n",
      "Number of steps 39\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  58\n",
      "Number of steps 15\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  59\n",
      "Number of steps 92\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  60\n",
      "Number of steps 35\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  61\n",
      "Number of steps 28\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  62\n",
      "Number of steps 60\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  63\n",
      "Number of steps 17\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  64\n",
      "Number of steps 31\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  65\n",
      "Number of steps 26\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  66\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  67\n",
      "Number of steps 76\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  68\n",
      "Number of steps 16\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  69\n",
      "Number of steps 84\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  70\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  71\n",
      "Number of steps 64\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  72\n",
      "Number of steps 45\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  73\n",
      "Number of steps 33\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  74\n",
      "Number of steps 22\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  75\n",
      "Number of steps 11\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  76\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  77\n",
      "Number of steps 26\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  78\n",
      "Number of steps 15\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  79\n",
      "Number of steps 31\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  80\n",
      "Number of steps 12\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  81\n",
      "Number of steps 11\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  82\n",
      "Number of steps 52\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  83\n",
      "Number of steps 27\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  84\n",
      "Number of steps 57\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  85\n",
      "Number of steps 89\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  86\n",
      "Number of steps 47\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  87\n",
      "Number of steps 37\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  88\n",
      "Number of steps 40\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  89\n",
      "Number of steps 73\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  90\n",
      "Number of steps 8\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  91\n",
      "Number of steps 41\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  92\n",
      "Number of steps 42\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  93\n",
      "Number of steps 8\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  94\n",
      "Number of steps 12\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  95\n",
      "Number of steps 60\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  96\n",
      "Number of steps 40\n",
      "Reward: 0.0\n",
      "****************************************************\n",
      "EPISODE  97\n",
      "Number of steps 93\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  98\n",
      "Number of steps 64\n",
      "Reward: 1.0\n",
      "****************************************************\n",
      "EPISODE  99\n",
      "Number of steps 99\n",
      "Reward: 0.0\n",
      "Total rewards: 69.0 /100\n"
     ]
    }
   ],
   "source": [
    "#slippery 8x8 qtable\n",
    "#test_qtable = np.loadtxt('C:\\\\Users\\\\ETCH\\\\Desktop\\\\Github\\\\ANT61 Internship\\Week 2\\\\FrozenLake8x8-v1 slippery\\\\120000_0.01_0.999_0.0001_5e-05.csv', delimiter =\",\")\n",
    "#non-slippery 8x8 qtable\n",
    "#test_qtable = np.loadtxt('C:\\\\Users\\\\ETCH\\\\Desktop\\\\Github\\\\ANT61 Internship\\Week 2\\\\FrozenLake8x8-v1\\\\60000_0.75_0.9_0.0001_5e-05.csv', delimiter =\",\")\n",
    "test_model(qtable=test_qtable)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a92ebb1a32b68af07ba4ae21d89671d5ef172113d2414e62053b015791ee503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
